{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GhpFIvuhh2h1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:47:27.638445: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-08 18:47:27.716709: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-08 18:47:33.058710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "import subprocess\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.lib.format.open_memmap('X_train.npy', mode='r', dtype='float32')\n",
    "y_train=np.lib.format.open_memmap('y_train.npy', mode='r', dtype='float32')\n",
    "X_val=np.lib.format.open_memmap('X_val.npy', mode='r', dtype='float32')\n",
    "y_val=np.lib.format.open_memmap('y_val.npy', mode='r', dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "eGTALnPhTWaf"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-er5jSYZxtaC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(1000, 21, 1))\n",
    "\n",
    "conv1 = Conv2D(filters=128, kernel_size=(4, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "conv2 = Conv2D(filters=128, kernel_size=(8, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "conv3 = Conv2D(filters=128, kernel_size=(16, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "#conv4 = Conv2D(filters=128, kernel_size=(32, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(997, 1))(conv1)\n",
    "pool2 = MaxPooling2D(pool_size=(993, 1))(conv2)\n",
    "pool3 = MaxPooling2D(pool_size=(985, 1))(conv3)\n",
    "#pool4 = MaxPooling2D(pool_size=(969, 1))(conv4)\n",
    "\n",
    "flatten1 = Flatten()(pool1)\n",
    "flatten2 = Flatten()(pool2)\n",
    "flatten3 = Flatten()(pool3)\n",
    "#flatten4 = Flatten()(pool4)\n",
    "\n",
    "bn1 = BatchNormalization()(flatten1)\n",
    "bn2 = BatchNormalization()(flatten2)\n",
    "bn3 = BatchNormalization()(flatten3)\n",
    "#bn4 = BatchNormalization()(flatten4)\n",
    "\n",
    "concat = Concatenate()([bn1, bn2, bn3])\n",
    "\n",
    "dense1 = Dense(512)(concat)\n",
    "bn5 = BatchNormalization()(dense1)\n",
    "act1 = Activation('relu')(bn5)\n",
    "dropout1= Dropout(0.3)(act1)\n",
    "\n",
    "dense2 = Dense(512)(dropout1)\n",
    "bn6 = BatchNormalization()(dense2)\n",
    "act2 = Activation('relu')(bn6)\n",
    "dropout2=Dropout(0.3)(act2)\n",
    "\n",
    "dense3 = Dense(512)(dropout2)\n",
    "#bn6 = BatchNormalization()(dense3)\n",
    "#act3 = Activation('relu')(bn6)\n",
    "#dropout3=Dropout(0.3)(act3)\n",
    "\n",
    "output_layer = Dense(2, activation='sigmoid')(dropout2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(1000, 21, 1))\n",
    "\n",
    "conv1 = Conv2D(filters=128, kernel_size=(4, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "conv2 = Conv2D(filters=128, kernel_size=(8, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "conv3 = Conv2D(filters=128, kernel_size=(16, 21), strides=(1, 1), padding='valid', activation='relu')(input_layer)\n",
    "\n",
    "pool1 = MaxPooling2D(pool_size=(997, 1))(conv1)\n",
    "pool2 = MaxPooling2D(pool_size=(993, 1))(conv2)\n",
    "pool3 = MaxPooling2D(pool_size=(985, 1))(conv3)\n",
    "\n",
    "flatten1 = Flatten()(pool1)\n",
    "flatten2 = Flatten()(pool2)\n",
    "flatten3 = Flatten()(pool3)\n",
    "\n",
    "bn1 = BatchNormalization()(flatten1)\n",
    "bn2 = BatchNormalization()(flatten2)\n",
    "bn3 = BatchNormalization()(flatten3)\n",
    "\n",
    "concat = Concatenate()([bn1, bn2, bn3])\n",
    "\n",
    "dense1 = Dense(512)(concat)\n",
    "bn4 = BatchNormalization()(dense1)\n",
    "act1 = Activation('relu')(bn4)\n",
    "#dropout1= Dropout(0.2)(act1)\n",
    "\n",
    "dense2 = Dense(512)(act1)\n",
    "bn5 = BatchNormalization()(dense2)\n",
    "act2 = Activation('relu')(bn5)\n",
    "#dropout2=Dropout(0.2)(act2)\n",
    "\n",
    "output_layer = Dense(2, activation='sigmoid')(act2)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6JaK9trOTdV-",
    "outputId": "550ff562-84db-4ef7-e650-23e085605788"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1000, 21, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 997, 1, 128)  10880       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 993, 1, 128)  21632       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 985, 1, 128)  43136       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1, 1, 128)    0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 128)   0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 128)          0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 128)          0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 128)         512         ['flatten[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 128)         512         ['flatten_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 128)         512         ['flatten_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['batch_normalization[0][0]',    \n",
      "                                                                  'batch_normalization_1[0][0]',  \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 512)          197120      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 512)         2048        ['dense[0][0]']                  \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 512)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          262656      ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 512)         2048        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 512)          0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 2)            1026        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 542,082\n",
      "Trainable params: 539,266\n",
      "Non-trainable params: 2,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLfim2bmQVZ7",
    "outputId": "235731ed-0adf-4816-ef57-b5ebeae1dce8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 18:50:11.770634: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 16304568000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "759/759 [==============================] - 263s 342ms/step - loss: 0.3811 - binary_accuracy: 0.8305 - val_loss: 0.3593 - val_binary_accuracy: 0.8449\n",
      "Epoch 2/40\n",
      "759/759 [==============================] - 253s 333ms/step - loss: 0.2753 - binary_accuracy: 0.8861 - val_loss: 0.2970 - val_binary_accuracy: 0.8753\n",
      "Epoch 3/40\n",
      "759/759 [==============================] - 257s 339ms/step - loss: 0.2237 - binary_accuracy: 0.9099 - val_loss: 0.2959 - val_binary_accuracy: 0.8782\n",
      "Epoch 4/40\n",
      "759/759 [==============================] - 261s 344ms/step - loss: 0.1883 - binary_accuracy: 0.9251 - val_loss: 0.2933 - val_binary_accuracy: 0.8839\n",
      "Epoch 5/40\n",
      "759/759 [==============================] - 263s 346ms/step - loss: 0.1590 - binary_accuracy: 0.9368 - val_loss: 0.3038 - val_binary_accuracy: 0.8860\n",
      "Epoch 6/40\n",
      "759/759 [==============================] - 264s 347ms/step - loss: 0.1352 - binary_accuracy: 0.9471 - val_loss: 0.3141 - val_binary_accuracy: 0.8878\n",
      "Epoch 7/40\n",
      "759/759 [==============================] - 264s 348ms/step - loss: 0.1166 - binary_accuracy: 0.9549 - val_loss: 0.3375 - val_binary_accuracy: 0.8857\n",
      "Epoch 8/40\n",
      "759/759 [==============================] - 264s 348ms/step - loss: 0.1005 - binary_accuracy: 0.9615 - val_loss: 0.3579 - val_binary_accuracy: 0.8844\n",
      "Epoch 9/40\n",
      "759/759 [==============================] - 264s 348ms/step - loss: 0.0852 - binary_accuracy: 0.9677 - val_loss: 0.3757 - val_binary_accuracy: 0.8844\n",
      "Epoch 10/40\n",
      " 39/759 [>.............................] - ETA: 3:54 - loss: 0.0565 - binary_accuracy: 0.9804"
     ]
    }
   ],
   "source": [
    "#with batch size mentioned\n",
    "#with early stopping\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.001, # minimium amount of change to count as an improvement\n",
    "    patience=10, # how many epochs to wait before stopping\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['binary_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val,y_val),\n",
    "    batch_size=256,\n",
    "    callbacks=[early_stopping],\n",
    "    epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "21O3WxMGRdXy",
    "outputId": "fa9fa491-c418-4764-85ac-830976d8a208"
   },
   "outputs": [],
   "source": [
    "# Show the learning curves\n",
    "import matplotlib\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lq-3DTzfdKTV"
   },
   "outputs": [],
   "source": [
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gEtiNB0-UHBB",
    "outputId": "26b07cb7-5b89-4814-cba5-07eb6ca4c126"
   },
   "outputs": [],
   "source": [
    "os.mkdir('model_06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving history\n",
    "history_df.to_csv('model_06/model_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Replace 'model' with the name of your trained model\n",
    "model_name = 'model_06/model_06'\n",
    "\n",
    "# Save the model architecture as a JSON file\n",
    "model_json = model.to_json()\n",
    "with open(model_name + '.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights as an H5 file\n",
    "model.save_weights(model_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B8uib7kOcg2J"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_val[:,1], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
